---
title: "Approaching Gen AI Use with Compassion"
date: October 20, 2025
author: Grace Tompkins
format: html
categories: 
  - reflection
  - teaching
  - Gen AI
image: "images/chatgpt_oct202025.jpg"
---

The overuse of generative artificial intelligence ("Gen AI") is easily one of the trickiest things to handle in my job. It did not come as a surprise when I found out a number of students were generating their answers using Gen AI on a recent project I assigned to my graduate student class. It's an easy way to get an answer (it might not be right, but at least it's something) with minimal effort. Copy and paste the question. Copy and paste the response. Rinse, and repeat.

I was pretty clear at the start of term about my expectations. I discussed how Gen AI was useful for debugging, like an advanced search engine. I even showed them live in class how I searched key words, and that the AI Summary that appeared on Google was often helpful. I told them copying questions into Chat GPT and using the answer was plagiarism. [We even discussed the environmental impacts of Gen AI overuse.](https://earth.org/environmental-impact-chatgpt/)

And so, upon my discovery of the use of Gen AI on a major project, my initial reaction was frustration. I was frustrated by the inappropriate use, code plagiarism, and non-human-like answers to reflective questions. Then came a bit of sadness. Did I not teach them well enough to be confident in their skills? Do my students think they aren't good enough? And then after drafting and deleting a few snarky emails.. the compassion hit. Are these students facing barriers that are causing them to turn to Gen AI?

As a recent graduate, I knew how demanding graduate school was outside of coursework. Instead of pointing fingers and berating my students for academic misconduct (which really, it is. I am not dismissing the behaviour), I decided to talk to them. I first told my entire class I was disappointed by the AI use. I gave them a chance to come forward to talk to me about their assessments. I told them honesty was the best policy and for a first offence, nothing would be escalated beyond this course. I understood the temptation to use it.

I then directly emailed students who I suspected used Gen AI for a large portion of their assignment. I sent them (some form of) the following:

> I am a bit concerned about the sophisticated code used that included methods beyond the scope of the course, and the writing/rationales provided in your answers for \[assignment\]. \
> \
> I believe that honesty is the best policy, so if ChatGPT or any other generative AI software was used on this assessment for more than just debugging/using an advanced search engine, now is your chance to explain how you used it for your assessment. You will receive a 0 on questions that are clearly plagiarized, however I will not escalate it beyond this course. It will not impact your academic record or anything. There is no judgement - I understand the temptation to use LLMs to assist with homework. However for this assessment, it is not acceptable to use it in this way. Let me be super clear - I do not think that this assessment was 100% plagiarized, but there are some of red flags. You will not receive 0 for the entire assessment nor the course.\
> \
> If you did not use ChatGPT, please describe to me your coding experience (for example, when did you learn \[advanced method\] and why did you choose it?) and how you went about choosing your research questions and writing your rationals.\
> \
> I apologize in advance if this assessment was a genuine attempt and I've flagged it as suspicious.\
> \
> If you have any questions at all, or would like to discuss this further, please let me know.\
> \
> Thank you very much for your time.
>
> Grace

Every student the teaching team flagged did take the opportunity to talk to me directly about the AI use. Most were very regretful, and admitted that their use was inappropriate. Only one doubled-down and sent back a summary explaining their coding experience and a justification for the methods used. I was receptive of this. In all cases, our discussions were open and honest. There were no fingers pointed, and I told them that this did not affect their relationship with me as an instructor and I appreciated their honesty. I do think it takes lot of guts to come forward and admit you did something wrong. \
\
In our conversations, students admitted they used it for a variety of reasons, including being too overwhelmed with other obligations, have personal matters affecting their ability to complete the assessments on time, and even being embarrassed of their grammar/writing skills. While the use was inappropriate, I empathized. The conversation that struck me the most was about language barriers. I assured the student that I'd rather parse through some imperfect sentences than a robotic response. After all, this isn't *really* a communications course.

I went back and forth about how to deal with this. It is unfair for those to put in the work to grade plagiarized assignments the same. So, for obvious plagiarism, I gave 0 for the question. And I think the ability of the teaching team to sniff out AI use scared them a bit, so I do hope that the second part of this project will be a truer reflection of my students' abilities. I'm mostly satisfied with the outcome of this, as I do think students will think twice before turning to AI, and use it in a more honest way where appropriate.

These students are so bright. I wish they could see that their own work is enough. This case has certainly got me thinking about the future of Gen AI in the classroom, and how to navigate it in the future. \
\
