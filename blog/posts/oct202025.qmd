---
title: "Approaching Gen AI Use with Compassion"
date: October 20, 2025
author: Grace Tompkins
format: html
categories: 
  - Reflection
  - Teaching
  - Gen AI
image: "images/chatgpt_oct202025.jpg"
---

The overuse of generative artificial intelligence ("Gen AI") is easily one of the trickiest things to handle in my job. It did not come as a surprise when I found out a number of students were generating their answers using Gen AI on a recent project I assigned to my graduate student class. It's an easy way to get an answer (it might not be right, but at least it's something) with minimal effort. Copy and paste the question. Copy and paste the response. Rinse, and repeat.

I was pretty clear at the start of term about my expectations. I discussed how Gen AI was useful for debugging, like an advanced search engine. I even showed them live in class how I searched key words, and that the AI Summary that appeared on Google was often helpful. I told them copying questions into Chat GPT and using the answer was plagiarism. [We even discussed the environmental impacts of Gen AI overuse.](https://earth.org/environmental-impact-chatgpt/)

And so, upon my discovery of the use of Gen AI on a major project, my initial reaction was frustration. I was frustrated by the inappropriate use, code plagiarism, and non-human-like answers to reflective questions.

As a recent graduate, I knew how demanding graduate school was outside of coursework. Instead of pointing fingers and berating my students for academic misconduct (which really, it is. I am not dismissing the behaviour), I decided to talk to them. I first told my entire class I was disappointed by the AI use. I gave them a chance to come forward to talk to me about their assessments. I told them honesty was the best policy and for a first offence, nothing would be escalated beyond this course. I understood the temptation to use it.

I then directly emailed students who I suspected used Gen AI for a large portion of their assignment. I sent them an email asking if AI was used, and if not, where they learned the methods that were used in the paper and to re-justify their answers.

Every student the teaching team flagged did take the opportunity to talk to me directly about the AI use. Most were very regretful, and admitted that their use was inappropriate. In all cases, our discussions were open and honest. There were no fingers pointed, and I told them that this did not affect their relationship with me as an instructor and I appreciated their honesty. I genuinely do think it takes lot of guts to come forward and admit you did something wrong.\
\
In our conversations, students admitted they used it for a variety of reasons, including being too overwhelmed with other obligations, have personal matters affecting their ability to complete the assessments on time, and even being embarrassed of their grammar/writing skills. While the use was inappropriate, I empathized. The conversation that struck me the most was about language barriers. I assured the student that I'd rather parse through some imperfect sentences than a robotic response. After all, this isn't *really* a communications course.

I went back and forth about how to deal with this. It is unfair for those to put in the work to grade plagiarized assignments the same. So, for obvious plagiarism, I gave 0 for the question. And I think the ability of the teaching team to sniff out AI use scared them a bit, so I do hope that the second part of this project will be a truer reflection of my students' abilities. I'm mostly satisfied with the outcome of this, as I do think students will think twice before turning to AI, and use it in a more honest way where appropriate.

I do think a little bit of compassion is needed in these situations. These students are so bright - I wish they could see that their own work is enough. This case has certainly got me thinking about the future of Gen AI in the classroom, and how to navigate it in the future. \
